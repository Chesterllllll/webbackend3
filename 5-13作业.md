<!--
 * @Author: your name
 * @Date: 2021-05-31 20:34:20
 * @LastEditTime: 2021-06-05 19:33:29
 * @LastEditors: Please set LastEditors
 * @Description: In User Settings Edit
 * @FilePath: \webbackend4\5-13作业.md
-->
### 阅读思考题
数据架构是大型Web应用系统架构设计中的重要组成部分，请阅读《亿级流量系统架构》系列文章，总结一下在面对分布式、高并发、高可用、高性能、海量数据等技术挑战时可以采取的一些措施，并谈谈自己对这些方案的理解。
如何承载百亿级数据存储：http://www.imooc.com/article/284302
如何设计高容错的分布式架构：http://www.imooc.com/article/284393
如何设计承载百亿流量的高性能架构：http://www.imooc.com/article/284395
如何设计每秒数十万并发查询的高并发架构：http://www.imooc.com/article/284473
如何设计全链路99.99%高可用架构：http://www.imooc.com/article/284474
#### 措施
##### 1.离线计算和实时计算进行拆分
① 离线计算链路：每天凌晨，我们将业务系统MySQL库中的昨天以前的数据，作为离线数据导入Hadoop HDFS中进行离线存储，然后凌晨就基于Hive / Spark对离线存储中的数据进行离线计算。

② 实时计算链路：每天零点过后，当天最新的数据变更，全部还是走之前的老路子，秒级同步业务库的数据到数据平台存储中，接着就是数据平台系统定时运行大量的SQL进行计算。同时在每天零点的时候，还会从数据平台的存储中清理掉昨天的数据，仅仅保留当天一天的数据而已。实时计算链路最大的改变，就是仅仅在数据平台的本地存储中保留当天一天的数据而已，这样就大幅度降低了要放在MySQL中的数据量了。

但是这种方式只是治标不治本，如果单日的数据量过大，比如双十一，当天的数据太大，可能导致SQL计算过慢，导致数据平台卡死，CPU开始，或者单日数据量超过数据库的存储上限，也无法解决。

##### 2.根据具体业务场景，从0开始定制开发自己的一套数据平台系统架构
这是非常好的想法，因为普通的方法都是普适性的，而普适性就代表着他针对性没有那么强，而面对具体问题时，我们要具体分析，用特定的方法去解决特定的问题，这样效率才高。

##### 3.分库分表解决数据扩容问题
原因：一旦单台数据库服务器无法存储下当日的数据，该怎么办？

我们需要将一个库拆分为多库，不用的库放在不同的数据库服务器上，同时每个库里放多张表。采用这套分库分表架构之后，可以做到每个数据库服务器放一部分的数据，而且随着数据量日益增长，可以不断地增加更多的数据库服务器来容纳更多的数据，做到按需扩容。同时，每个库里单表分为多表，这样可以保证单表数据量不会太大，控制单表的数据量在几百万的量级，基本上性能优化到极致的SQL语句跑起来效率还是不错的，秒级出结果是可以做到的。

##### 4.读写分离降低数据库服务器的负载
原因：就是现在如果对每个数据库服务器又是写入又是读取的话，会导致数据库服务器的CPU负载和IO负载非常的高！
我们可以在数据平台中嵌入纯自研的滑动窗口计算引擎

##### 5.离线计算链路的性能优化
分库分表和读写分离能解决实时计算链路的问题，但离线计算链路也有性能问题。加入每天导入全量数据来进行计算，性能低下。
全量计算转增量计算：每天数据在导入hadoop之后，都会针对数据的业务时间戳来分析和提取出来每天变更过的增量数据，将这些增量数据放入独立的增量数据表中。

同时需要根据具体的业务需求，自动分析数据计算的基础血缘关系，有可能增量数据需要与部分全量数据混合才能完成计算，此时可能会提取部分全量历史数据，合并完成计算。计算完成之后，将计算结果与历史计算结果进行合并。

在完成这个全量计算转增量计算的过程之后，离线计算链路在凌晨基本上百亿级别的数据量，只要对昨天的增量数据花费一两个小时完成计算之后，就可以完成离线计算的全部任务，性能相较于全量计算提升至少十倍以上。

##### 6.如何避免系统单点故障
使用active-standby的高可用架构，也就是一共部署在两台机器上，但是同一时间只有一台机器是会运行的，但是另外一台机器是备用的。处于active状态的系统会将滑动窗口计算引擎的计算状态和结果写入zookeeper中，作为元数据存储起来。

也就是说我们不能寄希望于机器永远不宕机，我们要随时做好机器会宕机的准备，做好充分的故障预测，高可用架构以及故障演练，保证在各种场景下都可以运行，或者说，在无法运行的情况下，如何以最快速度恢复系统，保持好数据的更新。

##### 7.数据平台系统的计算负载越来越高，采用Master-slave
将数据平台系统彻底重构和设计为一套分布式的计算系统，将任务调度与任务计算两个职责进行分离，有一个专门的Master节点负责读取切分好的数据分片（也就是所谓的时间窗口，一个窗口就是一个数据分片），然后将各个数据分片的计算任务分发给多个Slave节点。

Slave节点的任务就是专门接收一个一个的计算任务，每个计算任务就是对一个数据分片执行一个几百行到上千行的复杂SQL语句来产出对应的数据分析结果。

同时对Master节点，我们为了避免其出现单点故障，所以还是沿用了之前的Active-Standby架构，Master节点是在线上部署一主一备的，平时都是active节点运作，一旦宕机，standby节点会切换为active节点，然后自动调度运行各个计算任务。

##### 8.弹性计算资源调度机制
原因：某台Slave机器挤压了大量计算任务一直迟迟得不到处理，主要由于系统的高峰和低谷的数据差异导致的。在高峰期，瞬时涌入的数据量很大，很可能某个数据分片包含的数据量过大，达到普通数据分片的几倍甚至几十倍，并且截止到目前为止的计算操作，其实还是基于几百行到上千行的复杂SQL落地到MySQL从库中去执行计算的。还有就是每个计算任务对应一个数据分片和一个SQL，但是不同的SQL执行效率不同，有的SQL可能只要200毫秒就可以结束，有的SQL要1秒，所以不同的SQL执行效率不同，造成了不同的计算任务的执行时间的不同。

因此，我们又专门在Master节点中加入了计算任务metrics上报、计算任务耗时预估、任务执行状态监控、机器资源管理、弹性资源调度等机制。也就是说：
① Master节点会实时感知到各个机器的计算任务执行情况、排队负载压力、资源使用等情况。
② 同时还会收集各个机器的计算任务的历史metrics
③ 接着会根据计算任务的历史metrics、预估当前计算任务的耗时、综合考虑当前各Slave机器的负载，来将任务分发给负载较低的Slave机器。

##### 9.分布式系统高容错机制
原因：① 某个Slave节点在执行过程中突然宕机 ② 某个计算任务执行时间过长 ③ 某个计算任务执行失败
因此，Master节点内需要实现一套针对Slave节点计算任务调度的容错机制，大体思路如下：
① Master节点会监控各个计算任务的执行状态，同时也会监控各个Slave节点的运行状态
② 如果说某个Slave宕机了，那么此时Master就会将那个Slave没执行完的计算任务重新分配给其他的Slave节点
③ 如果说某个Slave的计算任务执行失败了，同时重试几次之后还是失败，那么Master会将这个计算任务重新分配给其他的Slave节点来执行
④ 如果说某个计算任务在多个Slave中无法成功计算的话，此时会将这个计算任务储存在一个延时内存队列中，间隔一段时间过后，比如说等待高峰期故去，然后再重新尝试执行这个计算任务
⑤ 如果某个计算任务等待很长时间都没成功执行，可能是hang死了，那么Master节点会更新这个计算任务的版本号，然后分配计算任务给其他的Slave节点来执行。
⑥ 之所以要更新版本号，是为了避免说，新分配的Slave执行完毕写入结果之后，之前的那个Slave hang死了一段时间恢复了，接着将计算结果写入存储覆盖正确的结果。用版本号机制可以避免这种情况的发生。

##### 10.计算与存储分离的架构
原因：数据的存储和计算混在了一个地方，都在一个MySQL库里，单台MySQL数据库服务器，我们一般是不会让他的高峰期并发请求超过2000/s的，因为一旦达到每秒几千的请求，根据当时线上的资源负载情况来看，很可能MySQL服务器负载过高会宕机。，假如说每天亿级流量的场景下，需要用8主8从这么多高配置的数据库服务器来抗，那如果是几十亿流量呢？甚至如果是百亿流量呢？难道不停的增加更多的高配置机器吗？很明显不可能。
因此先将数据的存储和计算这两件事情拆开。
① 数据直接写入一个存储，仅仅只是简单的写入即可
② 然后在计算的时候从数据存储中提取你需要的那个数据分片里的可能就一两千条数据，写入另外一个专用于计算的临时表中，那个临时表内就这一两千条数据，然后运行你的各种复杂SQL即可。
这样的方案，首先数据存储只要支撑高并发的写入，日百亿流量的话，高峰每秒并发会达到几十万，撑住这就可以了。然后支持计算引擎通过简单的操作从数据存储里提取少量数据就OK。

##### 11.自研纯内存SQL计算引擎
原因：仅仅只是将MySQL作为一个临时表来计算了，主要就是用他的复杂SQL语法的支持。但是问题是，对MySQL的并发量虽然大幅度降低了，可是还并不算太低。因为大量的数据分片要计算，还是需要频繁的读写MySQL。
可以根据特定业务场景，只需要研发出针对少数语法的SQL引擎就行。接着就将系统彻底重构为不再依赖MySQL，每次从kv存储中提取一个数据分片之后，直接放入内存中，然后用我们自研的SQL计算引擎来在纯内存里针对一个数据分片执行各种复杂的SQL。而纯内存操作的性能十分优越，而且不再依赖MySQL，就不需要维护复杂的分库分表等等东西。
而且消除对MySQL的依赖有另外一个好处，数据库的机器总是要高配置的，但是Slave机器主要4核8G的普通虚拟机就够了，分布式系统的本质就是尽量利用大量的廉价普通机器就可以完成高效的存储和计算。

##### 12.MQ削峰以及流量控制
我们如果应对的是高并发的非实时响应的写入请求的话，完全可以使用MQ中间件先抗住海量的请求，接着做一个中间的流量分发系统，将流量异步转发到kv存储中去，同时这个流量分发系统可以对高并发流量进行控制。
比如说如果瞬时高并发的写入真的导致后台系统压力过大，那么就可以由流量分发系统自动根据我们设定的阈值进行流量控制，避免高并发的压力打垮后台系统。

##### 13.数据的动静分离架构
原因：每次如果Slave节点都是对一个数据分片提取相关联的各种数据出来然后进行计算，其实是没必要的！

如果你的SQL要对一些表进行关联计算，里面涉及到了一些大部分时候静态不变的数据，那些表的数据一般很少改变，因此没必要每次都走网络请求从kv存储里提取那部分数据。
我们其实完全可以在Slave节点对这种静态数据做个轻量级的cache，然后只有数据分片里对应的动态改变的数据才从kv存储来提取数据。
通过这个数据的动静分离架构，我们基本上把Slave节点对kv集群的网络请求降低到了最少，性能提升到了最高。

##### 14.分库分表 + 读写分离
原因：日益膨胀的离线计算结果，终端的商家用户就可以随意的查询MySQL里的数据分析结果，支撑自己的决策，他可以看当天的数据分析报告，也可以看历史上任何一段时期内的数据分析报告。假如每天增量数据是10亿，那么每天计算完以后的结果大致会是千万级，你可以算他是计算结果有5000万条数据吧，每天5000万增量数据写入离线的MySQL中，会导致用户在查询分析报告的时候速度极慢。

采用之前 3 4 的措施。

##### 15.数据的冷热分离架构
原因： 每秒10万查询的高并发挑战，假如使用的商户极多，并且用户开了数据分析页面后，js脚本定时发送请求，可能导致每秒数十万查询的高并发挑战。

冷热数据分离。也就是说，将今日实时计算出来的热数据放在一个MySQL集群里，将离线计算出来的冷数据放在另外一个MySQL集群里。然后开发一个数据查询平台，封装底层的多个MySQL集群，根据查询条件动态路由到热数据存储或者是冷数据存储。
通过这个步骤的重构，我们就可以有效的将热数据存储中单表的数据量降低到更少更少，有的单表数据量可能就几十万，因为将离线计算的大量数据结果从表里剥离出去了，放到另外一个集群里去。此时大家可想而知，效果当然是更好了。

##### 16.自研Elasticsearch+HBase+纯内存的查询引擎
原因：冷数据存储，如果完全用MySQL来承载是很不靠谱的。冷数据的数据量是日增长不断增加，而且增速很快，每天都新增几千万。因此你的MySQL服务器将会面临不断的需要扩容的问题，而且如果为了支撑这1%的冷数据查询请求，不断的扩容增加高配置的MySQL服务器，很不合理。

因此针对这个冷数据的存储和查询的问题，我们最终选择了自研一套基于NoSQL来存储，然后基于NoSQL+内存的SQL计算引擎。具体来说，我们会将冷数据全部采用ES+HBase来进行存储，ES中主要存放要对冷数据进行筛选的各种条件索引，比如日期以及各种维度的数据，然后HBase中会存放全量的数据字段。

##### 17.实时数据存储引入缓存集群
原因：每个商家的实时数据其实不是频繁的变更的，在一段时间内，可能压根儿没变化，因此不需要高并发请求，每秒10万级别的全部落地到数据库层面吧？要全都落地到数据库层面，那可能要给每个主库挂载很多从库来支撑高并发读。

因此这里我们引入了一个缓存集群，实时数据每次更新后写入的时候，都是写数据库集群同时还写缓存集群的，是双写的方式。
然后查询的时候是优先从缓存集群来走，此时基本上90%以上的高并发查询都走缓存集群了，然后只有10%的查询会落地到数据库集群。

##### 18.MQ集群高可用方案 异步转同步 + 限流算法 + 限制性丢弃流量
MQ集群故障其实是有概率的，而且挺正常的，因为之前就有的大型互联网公司，MQ集群故障之后，导致全平台几个小时都无法交易，严重的会造成几个小时公司就有数千万的损失。我们之前也遇到过MQ集群故障的场景，但是并不是这个系统里。如果这个链路中，万一MQ集群故障了，怎么办。

##### 19.KV集群高可用保障方案 临时扩容Slave集群 + 内存级分片存储  + 小时级数据粒度
简单来说，就是一旦发现kv集群故障，直接报警。我们收到报警之后，就会立马启动临时预案，手动扩容部署N倍的Slave计算集群。
接着同样会手动打开流控集群的一个降级开关，然后流控集群会直接按照预设的hash算法分发数据到各个Slave计算节点。
这就是关键点，不要再基于kv集群存数据了，本身我们的Slave集群就是分布式计算的，那不是刚好可以临时用作分布式存储吗！直接流控集群分发数据到Slave集群就行了，Slave节点将数据留存在内存中即可。
然后Master节点在分发数据计算任务的时候，会保证计算任务分发到某个Slave节点之后，他只要基于本地内存中的数据计算即可。
将Master节点和Slave节点都重构一下，重构成本不会太高，但是这样就实现了本地数据存储 + 本地数据计算的效果了。

##### 20.实时计算链路高可用保障方案 计算任务重分配 + 主备切换机制
因为Slave节点宕机，Master节点感知到了，会重新分配计算任务给其他的计算节点；如果Master节点宕机，就会基于Active-Standby的高可用架构，自动主备切换。

##### 21.热数据高可用保障方案 自研缓存集群查询引擎 + JVM本地缓存 + 限流机制
如果是MySQL集群故障，我们采取的方案是：实时计算结果直接写入缓存集群，然后因为没有MySQL支撑，所以没法使用SQL来从MySQL中组装报表数据。
如果是缓存集群故障，我们会有一个查询平台里的本地缓存，使用ehcache等框架就可以实现，从mysql中查出来的数据在查询平台的jvm本地缓存里cache一下，也可以用作一定的缓存支撑高并发的效果。而且查询平台实现限流机制，如果查询流量超过自身承载范围，就限流，直接对查询返回异常响应。

##### 22.冷数据高可用保障方案 收集查询日志 + 离线日志分析 + 缓存高频查询
对最近一段时间用户发起的离线查询的请求日志进行收集，然后对请求日志在每天凌晨进行分析，分析出来那种每个用户会经常、多次、高频发起的冷数据查询请求，然后对这个特定的查询（比如特殊的一组条件，时间范围，维度组合）对应的结果，进行缓存。

#### 总结
在以上的解决方案里，我们可以看到，其实这些方案的解决不是一蹴而就的，不是在设计之初就能设计出来的，要根据具体的应用场景进行特定的实现，并且业务量的需求会不断增加，系统需要根据业务量的增加进行相应的改变，而且我发现，高可用是实际应用架构中非常重要的，因为其实运行的性能虽然十分重要，但如果可靠性不够，导致用户的数据丢失，这种情况带来的损失是无可估量的，因此在实际得应用系统中，必须将高可用性放在极高的位置进行考虑。